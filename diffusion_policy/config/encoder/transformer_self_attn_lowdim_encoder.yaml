_target_: diffusion_policy.model.vision.transformer_self_attn_lowdim_encoder.TransformerSelfAttnLowdimEncoder
shape_meta: ${task.shape_meta}
n_obs_steps: ${n_obs_steps}
query_embeddings: 
  _target_: torch.nn.Embedding
  num_embeddings: ${n_obs_steps}
  embedding_dim: ${embedding_dim}
keypoint_embeddings: 
  _target_: torch.nn.Embedding
  num_embeddings: ${task.num_keypoints}
  embedding_dim: ${embedding_dim}
rotary_embedder: 
  _target_: diffusion_policy.model.common.position_encodings.RotaryPositionEncoding2D
  feature_dim: ${embedding_dim}
positional_embedder:
  _target_: diffusion_policy.model.common.position_encodings.SinusoidalPosEmb
  dim: ${embedding_dim}
within_attn: 
  _target_: diffusion_policy.model.common.layers.FFWRelativeSelfAttentionModule
  embedding_dim: ${embedding_dim}
  num_attn_heads: 5
  num_layers: 4
across_attn: 
  _target_: diffusion_policy.model.common.layers.FFWRelativeCrossAttentionModule
  embedding_dim: ${embedding_dim}
  num_attn_heads: 5
  num_layers: 1
